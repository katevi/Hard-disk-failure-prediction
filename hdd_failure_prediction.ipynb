{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0afab6b6",
   "metadata": {},
   "source": [
    "## Free datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50cdf2",
   "metadata": {},
   "source": [
    "There are 4 datasets:\n",
    "- Backblaze dataset (https://www.kaggle.com/datasets/thedevastator/hard-drive-reliability-data-set; here are new datasets https://www.backblaze.com/b2/hard-drive-test-data.html)\n",
    "- University of California dataset (could be found at 2006 by following link http://cmrr.ucsd.edu/smart, found this via wayback machine now https://web.archive.org/web/20100611213812/http://cmrr.ucsd.edu/people/hughes/smart/dataset/harddrive1.zip)\n",
    "- Quantum Corporation dataset -- ??\n",
    "- Baidu dataset - this can be used probably (probably https://www.kaggle.com/datasets/drtycoon/baidu-hdds-dataset-2017 can be used, but it has 14 columns and there 23 columns in this dataset in papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61629228",
   "metadata": {},
   "source": [
    "## Sets of features used in the papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884e12a",
   "metadata": {},
   "source": [
    "### Machine Learning Methods for Predicting Failures in Hard Drives: A Multiple-Instance Application (University of California dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd2026",
   "metadata": {},
   "source": [
    " Attributes in the set of 25 are: GList1, PList, Servo1, Servo2, Servo3, Servo5, ReadError1, ReadError2, ReadError3,\n",
    "FlyHeight5, FlyHeight6, FlyHeight7, FlyHeight8, FlyHeight9, FlyHeight10, FlyHeight11, FlyHeight12, ReadEr-\n",
    "ror18, ReadError19, Servo7, Servo8, ReadError20, GList2, GList3, Servo10.\n",
    "\n",
    "Single attribute tests using rank-sum were run on all 25 attributes selected in Section 3.3 with 15 samples per pattern. Of these 25, only 8 attributes (Figure 9) were able to detect failures at sufficiently low false alarm rates: ReadError1, ReadError2, ReadError3, ReadError18, ReadError19, Servo7, GList3 and Servo10. Confirming the observations of the feature selection process, ReadError18 was the best attribute, with 27.6% detection at 0.06% false alarms.\n",
    "\n",
    "Using combinations of attributes in the rank-sum test can lead to improved results over single-attribute classifiers (Figure 11). The best single attributes from Figure 9 were ReadError1, ReadError3, ReadError18 and ReadError19. Using these four attributes and 15 samples per pattern, the rank-sum test detected 28.1% of the failures, with no measured false alarms. Higher detection rates (52.8%) can be had if more false alarms are allowed (0.7%). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3158fc8c",
   "metadata": {},
   "source": [
    "### Bayesian Approaches to Failure prediction for Disk Drives (Quantum dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e705ff",
   "metadata": {},
   "source": [
    "|Abbreviation | Description|\n",
    "|---|---|\n",
    "| RET | read error rate |\n",
    "| SUT | spinup time |\n",
    "| CSS | start-stop count |\n",
    "| GDC | grown defects count |\n",
    "| SKE | seek errors count |\n",
    "| POH | power-on hours |\n",
    "| RRT | calibration retries |\n",
    "| PCC | power cycles count |\n",
    "| RSE | read soft errors count |\n",
    "| DMC | CRC errors count |\n",
    "| OSS | offline surface scan |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ccc36",
   "metadata": {},
   "source": [
    "### Health Monitoring of Hard Disk Drive Based on Mahalanobis Distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5c1ac",
   "metadata": {},
   "source": [
    "**Most of the works used all of the data without selection or select the data with maximum distance between healthy drive and failed drives**. It is actually a supervised methodology based on the prior knowledge from which the drive's health status can be known.\n",
    "\n",
    "#### FMMEA method applying\n",
    "\n",
    "\n",
    "1. Potential failure mechanisms \n",
    "are determined by available mechanisms corresponding to the physical, electrical, chemical and mechanical stresses which can induce the failure. It is found that 60% of drives failures are mechanical, often resulting from the gradual degradation of the drive's performance. \n",
    "In HDD they are:\n",
    "- Head disk interface (HDI, including head and disk, also known as air bearing): Crack on head, broken head, head contamination, bad connection to electronics module; disk\n",
    "scratches, defect, bad servo pattern, flying height variation and modulation.\n",
    "- Head stack assembly: off-track, deformation.\n",
    "- Motors/bearings: motor failure, worn bearing, excessive run out, no spin.\n",
    "- Electronic module: circuit/chip failure, bad connection to drive or bus.\n",
    "\n",
    "2. Prioritization of Potential Failure Mechanisms\n",
    "\n",
    "- head disk interface as the dominant contributor to HDD reliability \n",
    "- the wear out, overstress of magnetic head and disk, and resonancehead assembly are categorized as potential failure mechanisms with high risk\n",
    "- spindle motor and control board have a failure mode in low priorities. \n",
    "\n",
    "\n",
    "**Corresponsdence between attributes and failure mechanisms**:\n",
    "- head flying height, data throughput performance, read/write errors, re-allocated sector count and drive calibration retries count can be recognized as HDI failure indicators. \n",
    "-  Seek error rate and seek time performance can be mainly attributed to head assembly issue.\n",
    "- The servo error count is a special case which can be induced by any component failures in the whole servo loop. Changes in spin up time and increases in drive temperature can reflect problems with spindle motor.\n",
    "- It is notable that a study published by Google suggested **very little correlation between failure rates and high temperature** based on 100,000 drives data [40]\n",
    "\n",
    "\n",
    "**In this study, the HDI and head assembly performance attributes are selected as candidates to assess the health ofHDD.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd58a8",
   "metadata": {},
   "source": [
    "Typical characteristics of SMART are:\n",
    "- Head flying height -- is the distance between the disk read/write head on a hard disk drive and the platter. Fly height variation can cause the media being insufficiently magnetized and the data are not readable. The physically bumping or banging during the HDD reading or writing process leading the head with strong vibration, which can induce the read/write failure. \n",
    "- Data throughput performance -- General throughput performance of the hard disk. Indicate problem with motor, servo or bearings.\n",
    "- Spin up time -- S.M.A.R.T. parameter indicates an average time (in milliseconds or seconds) of spindle spinup (from zero RPM (Revolutions Per Minute) to fully operational). The low value means it takes too long for the hard disk to a fully operational state.\n",
    "- Re-allocated sector count -- is the number of sectors that are marked as reallocated by the hard drive upon an error. A growing count is generally considered a bad sign and can result in hard drive failure.\n",
    "- Seek error rate -- \tRate of positioning errors of the read/write heads. Indicate problem with servo, head. High temperature can also cause this problem.\n",
    "- Seek time performance --  the average performance of seek operations of the hard disk’s magnetic heads.\n",
    "- Spin try recount -- Retry count of spin start attempts. Indicate problem with motor, bearings or power supply.\n",
    "- Drive calibration retries count -- Number of attempts to calibrate a drive. Indicate problem with motor, bearings or power supply.\n",
    "\n",
    "\n",
    "\n",
    "Here is the full [list](hdsentinel.com/smart/smartattr.php) of SMART parameters descriptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78cbf3d",
   "metadata": {},
   "source": [
    "### HMM, HSMM\n",
    "\n",
    "We then run our HMM and HSMM predictors and found four attributes provided good failure detection, namely, ReadError18, Servo2, Servo10, and FlyHeight7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b72600",
   "metadata": {},
   "source": [
    "### Autoencoders (Backblaze dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a823a5",
   "metadata": {},
   "source": [
    "SMART attributes used in the experiments:\n",
    "\n",
    "| SMART ID | Attribute Name |\n",
    "| --- | --- |\n",
    "| 1 | Read Error Rate |\n",
    "| 3 | Spin up time |\n",
    "| 4 | start stop count |\n",
    "| 5 | Reallocated sectors count| \n",
    "| 7 | Seek error rate |\n",
    "| 9 | Power on hours |\n",
    "| 10 | Spin retry count |\n",
    "| 12 | Power cycle count |\n",
    "| 183 | sata downshift error count |\n",
    "| 184 | End-to-End error / IOEDC | \n",
    "| 187 | Reported Uncorrectable Errors |\n",
    "|188 | Command Timeout | \n",
    "| 189 | High Fly Writes |\n",
    "| 190 | Temperature Difference |\n",
    "| 191 | G-sense Error Rate |\n",
    "| 192 | Unsafe Shutdown Count |\n",
    "| 193 | Load Cycle Count | \n",
    "| 194 | Temperature |\n",
    "| 197 | Current Pending Sector Count |\n",
    "| 198 | Uncorrectable Sector Count |\n",
    "| 199 | UltraDMA CRC Error Count |\n",
    "| 240 | Head Flying Hours |\n",
    "| 241  | Total LBAs Written |\n",
    "| 242 | Total LBAs Read |\n",
    "\n",
    "\n",
    "\n",
    "For the PCA method, we performed the transformation and selected the eigenvectors that resulted in features that\n",
    "preserve 90% of the variance, resulting in 8 features out of the 24 described in Table I. For the Autoencoders, it was trained a neural network architecture with hidden layers of size (15-8-15) and a output layer of size 24 (the number of dimensions of the input), with the ReLU activation function and the backpropagation algorithm with L2 regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad35e71",
   "metadata": {},
   "source": [
    "## Datasets EDAs\n",
    "\n",
    "Found very good repo with eda: https://github.com/awant/sd_failure_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02e347",
   "metadata": {},
   "source": [
    "### University of california dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = arff.loadarff('./uc/harddrive1.arff')\n",
    "df_uc = pd.DataFrame(data[0])\n",
    "\n",
    "df_uc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629f870",
   "metadata": {},
   "source": [
    "### Backblaze dataset analysis EDA\n",
    "#### Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Concatenating all datasets (one dataset per month 2017) to one\n",
    "df_bb = pd.concat(map(pd.read_csv, glob.glob(\"./backblaze/*.csv\")))\n",
    "df_bb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e232ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f98fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bb.groupby('model')['failure'].sum().sort_values(ascending=False).iloc[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb05440",
   "metadata": {},
   "source": [
    "Таким образом, датасет имеет 1031501 записей о жестких дисках, из которых 45 дисков отказали.\n",
    "Так как каждый поставщик дисков поставляет значения SMART параметров своим способом, правильнее выбрать одну модель диска и прогнозировать ее отказ. \n",
    "Так как больше всего отказавших дисков было модели ST4000DM000, можно взять эту модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d373141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb = df_bb.query('model == \"ST4000DM000\"')\n",
    "df_bb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4897c",
   "metadata": {},
   "source": [
    "24 отказавших диска для датасета из 486316 наблюдений --- очень маленькое количество, поэтому хочется взять датасет, где отказавших дисков больше.\n",
    "Нашла вот этот: https://www.kaggle.com/datasets/awant08/hard-drive-failure-prediction-st4000dm000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all datasets (one dataset per month 2017) to one\n",
    "df_bb = pd.concat(map(pd.read_csv, glob.glob(\"./backblaze_ST4000DM000/*.csv\")))\n",
    "df_bb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261b68d9",
   "metadata": {},
   "source": [
    "В этом датасете отказавших дисков больше, и они все одной модели.\n",
    "\n",
    "####  Data cleaning\n",
    "Будем работать с нормализованными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ee34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb.drop(['failure', 'serial_number'], inplace=True, axis=1)\n",
    "#df_bb.columns\n",
    "\n",
    "#df_bb_not_normalized = df_bb[df_bb.columns.drop(list(df_bb.filter(regex='normalized')))]\n",
    "#feat_names_not_normalized = df_bb_not_normalized.columns.values\n",
    "#print(\"Dataset with not normalized features values\", feat_names_not_normalized)\n",
    "#print(df_bb_not_normalized.shape)\n",
    "\n",
    "df_bb_normalized = df_bb[df_bb.columns.drop(list(df_bb.filter(regex='raw')))]\n",
    "feat_names_normalized = df_bb_normalized.columns.values\n",
    "print(\"Dataset with normalized features values\", feat_names_normalized)\n",
    "print(df_bb_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eadc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61324473",
   "metadata": {},
   "source": [
    "Как видим, в датасете есть много признаков без значений. Удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c92efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_values = df_bb_normalized.columns[df_bb_normalized.isnull().sum() <= 32]\n",
    "df_bb_normalized = df_bb_normalized[columns_with_values]\n",
    "df_bb_normalized.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec074f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['capacity_bytes'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d72e6a",
   "metadata": {},
   "source": [
    "У большинства дисков установлено значение capacity_bytes = 4000787030016. Удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_10_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951e3bd",
   "metadata": {},
   "source": [
    "Все наблюдения имеют значение признака smart_10_normalized = 100. Удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa450a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_188_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a144c9d",
   "metadata": {},
   "source": [
    "Почти все наблюдения имеют значение признака smart_188_normalized = 100. Удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f95ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_191_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c0177",
   "metadata": {},
   "source": [
    "Все наблюдения имеют значение признака smart_191_normalized = 100. Удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80713d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_192_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0aaf0f",
   "metadata": {},
   "source": [
    "Все наблюдения имеют значение признака smart_192_normalized = 100. Удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_199_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7828a3c",
   "metadata": {},
   "source": [
    "Все наблюдения имеют значение признака smart_199_normalized=200. Удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc99453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_240_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_241_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6257d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized['smart_242_normalized'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57654df",
   "metadata": {},
   "source": [
    "Рассмотренные выше признаки аналогично нужно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd74ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['capacity_bytes', 'smart_10_normalized', 'smart_188_normalized', 'smart_191_normalized', 'smart_192_normalized',\n",
    "                   'smart_199_normalized', 'smart_240_normalized', 'smart_241_normalized', 'smart_242_normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized = df_bb_normalized.drop(features_to_drop, axis=1)\n",
    "df_bb_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574eee85",
   "metadata": {},
   "source": [
    "В результате чистки осталось 18 признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862f8f8",
   "metadata": {},
   "source": [
    "Посмотрим на корелляции признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "string_columns = ['date', 'model']\n",
    "df_bb_numeric = df_bb_normalized.drop(columns=string_columns, axis=1)\n",
    "\n",
    "corr = df_bb_numeric.corr()\n",
    "#Plot figsize\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "#Generate Heat Map, allow annotations and place floats in map\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\")\n",
    "#Apply xticks\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "#Apply yticks\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e126a11",
   "metadata": {},
   "source": [
    "Из графика видно, что очень высокую корелляцию имеют признаки smart_194_normalized и smart_190_normalized. Такое значение корелляции кажется логичным, так как, исходя из [описания](https://ru.wikipedia.org/wiki/S.M.A.R.T.):\n",
    "- 190 --- Температура воздуха внутри корпуса жёсткого диска. Для дисков Seagate рассчитывается по формуле 100-HDA temperature. Для дисков Western Digital — 125-HDA.\n",
    "- 194 --- Здесь хранятся показания встроенного термодатчика для механической части диска — «банки» (HDA — Head and Disk Assembly). Информация снимается со встроенного термодатчика, которым служит одна из магнитных головок — обычно нижняя в банке. В битовых полях атрибута фиксируются текущая, минимальная и максимальная температура. Не все программы, работающие со SMART, правильно разбирают эти поля, так что к их показаниям стоит относиться критически.\n",
    "\n",
    "Поэтому можем удалить какой-либо из этих двух признаков. Удалим 190."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized = df_bb_normalized.drop(['smart_190_normalized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7024366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bb_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f9e90",
   "metadata": {},
   "source": [
    "#### Проверка гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc19da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
